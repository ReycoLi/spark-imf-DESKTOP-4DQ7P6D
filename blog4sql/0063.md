# 第63课：Spark SQL下Parquet内幕深度解密

标签： sparkIMF

---

##一：Spark SQL下的Parquet意义再思考

 1. **如果说HDFS是大数据时代分布式文件系统存储的事实标准的话，Parquet则是整个大数据时代文件存储格式的事实标准。**
 2. 速度更快：从使用Spark SQL操作普通文件CSV和Parquet文件的速度对比上来看，绝大多数情况下使用Parquet会比使用CSV等普通文件速度提升10倍左右（在一些普通文件系统无法在Spark上成功运行程序的情况下，使用Parquet很多时候都可以成功运行）。
 3. Parquet的压缩技术非常稳定出色，在Spark SQL中对压缩技术的处理可能无法正常的完成工作（例如会导致Lost Task、Lost Executor），但是此时如果使用Parquet就可以正常的完成；
 4. 极大的减少磁盘I/O，通常情况下能够减少75%的存储空间，由此可以极大的减少Spark SQL处理数据的时候的数据输入内容，尤其是在Spark 1.6.x 中下推过滤器在一些情况下可以极大的进一步减少磁盘的IO和内存的占用。
 5. Spark 1.6.x + Parquet极大的提升了数据扫描的吞吐量，这极大的提高了数据的查找速度，Spark 1.6和Spark 1.5.x相比较而言提升了大约1倍的速度，在Spark 1.6.x中操作Parquet时候CPU的使用也进行了极大的优化，有效的降低了CPU的使用。
 6. 采用Parquet可以极大的优化Spark的调度和执行，我们的测试表明Spark如果采用Parquet可以有效的减少Stage的执行消耗，同时可以优化执行路径。

##二：Spark SQL下的Parquet内幕解密

 1. 列式存储是以什么基本格式来存储数据的？基本表现上是树状数据结构，在内部有元数据的Table。
 2. 在具体的Parquet文件存储的时候有三个核心组成部分：
    * Storage Format：Parquet定义了具体的数据内部的类型和存储格式。
    * Object Model Converters：Parquet中负责计算框架中数据对象和Parquet文件中具体数据的映射。
    * Object Models：在Parquet中具有自己的Object Model定义的存储格式，例如说Avro具有自己的Object Model，但是Parquet在处理相关的格式的数据的时候会使用自己的Object Model来存储。

    映射完成后Parquet会进行自己的Column Encoding，然后存储成为Parquet格式的文件。
 3. Modules

The **parquet-format** project contains format specifications and Thrift definitions of metadata required to properly read Parquet files.

The **parquet-mr** project contains multiple sub-modules, which implement the core components of reading and writing a nested, column-oriented data stream, map this core onto the parquet format, and provide Hadoop Input/Output Formats, Pig loaders, and other java-based utilities for interacting with Parquet.

The **parquet-compatibility** project contains compatibility tests that can be used to verify that implementations in different languages can read and write each other’s files.

###举例说明：

```parquet
message AddressBook{
    required string owner;
    repeated string ownerPhoneNumbers;
    repeated group contacts{
        required string name;
        optional string phoneNumber;
    }
}
```
required（出现1次），optional（出现0次或者1次），repeated（出现0次或者多次）

这个Schema中每条记录表示一个人的AddressBook。有且只有一个owner，owner可以有0个或者多个ownerPhoneNumbers，owner可以有0个或者多个contacts。每个contact有且只有一个name，这个contact的phoneNumber可有可无。

* 第一点：就存储本身而言，只考虑叶子节点，我们的叶子节点owner、ownerPhoneNumber、name、phoneNumber。
* 第二点：在逻辑上而言Schema实质上是一个Table，

<table>
    <tr>
        <th colspan='4' style='text-align:center;'>AddressBook</th>
    </tr>
    <tr>
        <td rowspan='2'>owner</td>
        <td rowspan='2'>ownerPhoneNumber</td>
        <th>contacts</th>
    </tr>
    <tr>
        <td>name</td>
        <td>phoneNumber</td>
    </tr>
</table>

* 第三点：对于一个Parquet文件而言，数据会被分成Row Group（里面包含很多Column，每个Column具有几个非常重要的特性，例如Repetition Level、Definition Level）。
* 第四点：Column在Parquet中是以Page的方式存在的，Page中有Repetition Level、Definition Level等内容。
* 第五点：Row Group在Parquet中是数据读写的缓存单元，所以对Row Group的设置会极大的影响Parquet的使用速度和效率，所以如果是分析日志的话，我们一般建议把Row Group的缓存大小配置成大于256MB，很多人的配置都是大于1G，如果想带来最大化的运行效率强烈建议HDFS的Block大小和Row Group一致。
record shredding and assembly algorithm 
* 第六点：在实际存储的时候，把一个树状结构，通过巧妙的编码算法，转换成二维表结构。

|Repetiton Level|	Definition Level|	Value|
|--|--|--|
|1|	2|	18610086859|
|0|	1|	“Spark”|
|0|	0|	NULL|

单词翻译：
repetition 重复
definition 定义

##Parquet官方

[官网：http://parquet.apache.org](http://parquet.apache.org)
[Parquet Document](http://parquet.apache.org/documentation/latest/)

##大公司可能会面试：你做Spark的话，底层文件格式是什么？ 如果你不说Parquet的话基本没戏了！
# 第56课：揭秘Spark SQL和DataFrame的本质

标签： sparkIMF

---

##一：Spark SQL与DataFrame

Spark SQL之所以是除了Spark Core以外最大的和最受关注的组件，原因是：

 1. 处理一切存储介质和各种格式的数据（你同时可以方便的扩展Spark SQL的功能来支持更多类型的数据，例如Kudu）；
 2. Spark SQL把数据仓库的计算能力推向了新的高度， 不仅是无敌的计算速度（Spark SQL比Shark快了至少一个数量级，而Shark比Hive快了至少一个数量级。尤其是在Tungsten成熟以后会更加无可匹敌），更为重要的是把数据仓库的计算复杂度推向了历史上全新的高度（Spark SQL后续推出的DataFrame可以让数据仓库直接使用机器学习、图计算等复杂的算法库来对数据仓库进行复杂的深度数据价值的挖掘）。
 3. **Spark SQL（DataFrame、DataSet）不仅是数据仓库的引擎，同时也是数据挖掘的引擎，更为重要的是 Spark SQL 是数据科学计算和分析的引擎！！**
 4. 后来的DataFrame让Spark（SQL）一举成为了大数据计算引擎的技术实现霸主（尤其是在Tungsten的强力支持下）！
 5. Hive+Spark SQL+DataFrame：目前至少是在中国所有的大数据项目至少90%无法逃脱该技术组合。
    * Hive：负责廉价的数据仓库存储
    * Spark SQL：负责高速的计算
    * DataFrame：负责复杂的数据挖掘


##二：DataFrame与RDD

 1. R和Python中都有DataFrame，Spark中的DataFrame从形式上看最大的不同点是其天生是分布式的。你可以简单的认为Spark中的DataFrame是一个分布式的Table，形式如下所述：
    |Name|Age|Tel|
    |---|---|---|
    |String|Int|Long|
    |String|Int|Long|
    |String|Int|Long|
    |String|Int|Long|

    而RDD是形如以下所示：
    |Person|
    | :---: |
    |Person|
    |Person|
    |Person|
    |Person|

 2. RDD和DataFrame的根本差异：
    * RDD是以Record为单位的，Spark在优化的时候无法洞悉Record内部的细节所以也就无法进行更深度的优化，这极大的限制了Spark SQL性能的提升！
    * DataFrame包含了每个Record的Metadata信息，也就是说DataFrame的优化是基于列内部的优化，而不是像RDD一样只能够基于行进行优化。

##三：Spark SQL企业级最佳实践

 1. 业界有几个做IT经典的阶段
    * 第一阶段：文件存储，c代码处理
    * 第二阶段：JavaEE+数据库，瓶颈和杀手是数据库不能进行分布式计算。一台机器处理不完数据，所以企业只能处理局部的部分数据。
    * 第三阶段：Hive，Hive计算能力有限，性能问题。
    王家林：我不认为那个时候搞一个Hive的大数据项目和你搞一个单机版本的数据库项目没有任何区别，但是结果就是你搞一个基于数据库的单机版本的项目你只能挣20万左右，但是你用Hive基于Hadoop搞一个大数据项目可能是300万或500万。
    * 第四阶段：Hive转向Spark SQL+Hive，计算能力是一个问题
    * 第五阶段：Hive+Spark SQL+DataFrame
    * 第六阶段：Hive+DataFrame+DataSet
 2. Hive和Spark SQL其实还有一个弊端就是：计算能力方面，所以后面推出了DataFrame。

##未来企业中各种系统，只要不是实时事务性系统，背后基本上全都是Spark，主要是Spark SQL

##面试高级工程师，一定会面试你JVM的问题，如果不面试说明只是把你当做普通工程师。
##作为一个高级工程师，必须掌握JVM性能优化

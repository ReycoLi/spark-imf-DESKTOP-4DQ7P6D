# 第80课：Spark SQL网站搜索综合案例实战

标签： sparkIMF

---

##项目：找出搜索平台上用户每天搜索排名前5名的产品

元数据：
* Date
* UserID
* Item
* City
* Device

##代码实战

```java
package com.dtspark.sparkapps.sql;

/**
 * 第80课：Spark SQL网站搜索综合案例实战（本demo可用来做面试）
 * Created by Limaoran on 2016/7/9.
 * 项目：找出搜索平台上用户每天搜索排名前5名的产品，The hottest！
 * 元数据：Date、UserID、Item、City、Device
 * 总体思路：混合使用了Spark SQL和Spark Core的内容
 *  第一步：原始的ETL，过滤数据后产生目标数据；在实际企业中可能过滤条件非常复杂（进行广播），使用RDD的filter等进行操作。
 *  第二步：对过滤后的目标数据进行指定条件的查询；查询条件也有可能非常复杂（进行广播），使用RDD的filter算子。
 *  第三步：由于商品是分为种类的，我们在得出最终结果之前，首先会基于商品进行UV（当然你也可以对用户访问商品的PV进行分析）
 *      此时我们要对商品进行UV计算的话，必须构建K-V的RDD，例如构建成为(date#item，userID)以方便进行groupByKey操作；
 *      在调用了groupByKey之后对user进行去重，并计算出每一天某种商品的UV，最终计算出来的结果的数据类型(date#item,UV)
 *  第四步：使用开窗函数row_number统计出每日商品UV前五名的内容。
 *      row_number() OVER(PARTITION BY date ORDER BY uv DESC ) rank
 *      此时会产生以date、item、uv为Row的DataFrame
 *  第五步：DataFrame转成RDD，根据日期进行分组并分析出每天排名前5位的热搜索Item；
 *  第六步：进行Key-Value交换，然后调用sortByKey进行点击热度排名；
 *  第七步：再次进行Key-Value交换，得出目标数据(date#Item,UV)的格式；
 *  第八步：通过RDD直接操作MySQL等把结果放入生产系统中的DB中，再通过Java EE等Server技术可视化结果
 *      以供市场营销人员、仓库调度系统、快递系统、管理决策人员使用数据创造价值。
 *      当然也可以放在Hive中，JavaEE等技术通过JDBC等连接访问Hive。
 *      当然也可以就放在Spark SQL中，通过Thrift技术供Java EE使用等；
 *      然是，如果是像双十一等时候，一般首选放在Redis中，这样可以实现类似秒杀系统的响应速度。
 */
public class TheTop5BySparkSQL {
    public static void main(String[] args) {
        throw new org.apache.commons.lang.NotImplementedException("这个项目还没有实现");
    }
}
```

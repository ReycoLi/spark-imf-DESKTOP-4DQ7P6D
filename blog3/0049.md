# 第49课：王家林谈Spark性能优化第五季！

标签： sparkIMF

---

##一：性能优化之数据本地性

 1. 数据本地性对分布式系统的性能而言是一件最为重要的事情（之一），程序运行本身包含代码和数据两部分，单机版本一般情况下很少考虑数据本地性的问题（因为数据在本地）。但是对于单机版本的程序由于数据本地性有PROCESS_LOCAL和NODE_LOCAL之分，所以我们还是尽量的让数据处于PROCESS_LOCAL。Spark作为分布式系统更加注意数据本地性，在Spark中数据本地性分为PROCESS_LOCAL、NODE_LOCAL、NO_PREF（在同样一台物理机器上）、RACK_LOCAL（同一机架）、ANY（数据可能在任何地方，包括在其他网络环境中。例如说百度云中，数据和计算集群不在同样的集群中，此时就是ANY的一种表现）。
 2. 对于ANY的情况，默认状态下性能会非常低下，此时强烈建议使用Tachyon；例如在百度云上，为了确保计算速度，就在计算集群和存储集群之间加入了Tachyon，通过Tachyon来从远程抓取数据，而Spark基于Tachyon来进行计算，这就更好的满足了数据本地性。
 3. 如果数据是PROCESS_LOCAL，但是此时并没有空闲的Core来运行我们的Task，此时Task就要等待，例如等待3000ms，3000ms内如果能够待运行的Task则直接运行，如果超过了3000ms，此时数据本地性就要退而求其次采用NODE_LOCAL，同样的道理NODE_LOCAL也会有等待的超时时间，以此类推。。。
 4. 如何配置Locality呢？可以统一采用spark.locality.wait来设置（例如设置5000ms），当然你可以分别设置spark.locality.wait.process、spark.locality.wait.node、spark.locality.wait.rack等；一般的具体设置是Locality优先级越高则可以设置越高的等待超时时间。

##二：RDD的自定义（以Spark on HBase为例）

 1. 第一步是定义RDD.getPartitions的实现：
    * createRelation具体确定HBase的连接方式和具体访问的表；
    * 然后通过HBase的API来获取Region的List；
    * 可以过滤出有效的数据；
    * 最后返回Region的Array[Partition]，也就是说一个Partition处理一个Region的数据，为更佳的数据本地性打下基础。
 2. <font color='red'>第二步是定义RDD.getPreferredLocations
    * 根据Split包含的Region信息来确定Region具体在什么节点上，这样Task在调度的时候就可以优先被调度到Region所在的机器上，最大化的提高数据本地性；</font>
 3. 第三步是RDD.compute
    * 根据Split中的Region等信息调用HBase的API来进行操作（主要是查询）

##作业：从网络上查询RDD封装MySQL的具体实现

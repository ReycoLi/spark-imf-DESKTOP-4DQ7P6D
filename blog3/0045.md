# 第45课：王家林谈Spark性能优化第一季！

标签： sparkIMF

---

性能优化本身是一个非常复杂的东西，也是一个非常具有技术含量的东西，也是真正能体现你水平的地方之一！

三大体现你水平的地方：

 1. 性能优化
 2. 出现故障的时候怎么快速定位故障和解决故障
 3. 从技术的角度而言：修改框架的能力

这三点你在任何一点如果说掌握的特别好的话，你都是非常难得的人才！大公司争着抢着要你！


##一：Spark性能优化核心基石

 1. Spark是采用Master-Slaves的模型进行资源管理和任务执行的管理的，对于资源管理：
    * 资源管理：Master-Workers，在一台机器上可以有多个Workers；
    * 任务执行：Driver-Executors，当在一台机器上分配多个Workers的时候那么默认情况下每个Worker都会为当前运行的应用程序分配一个Executor，但是我们可以修改配置来让每个Worker为我们当前的应用程序分配若干个Executor；程序运行的时候Tasks会被划分成为若干个Stages（Stage内部没有Shuffle，遇到Shuffle的时候会划分Stage），每个Stage里面包含若干个处理逻辑完全一样只是处理的数据不一样的Tasks，这些Tasks会被分配到Executor上去并行执行。
 2. 在Spark中可以考虑在Worker节点上使用固态硬盘以及把Worker的Shuffle结果保存到RAM Disk的方式来极大的提高性能。
 3. Spark Stage内部是一组计算逻辑完全相同但处理数据不同的分布式并行运行的Task构成，Stage内部的计算都以Pipeline的方式进行，不同的Stage之间是产生Shuffle的唯一方式。
 4. Spark集群在默认情况每台host上只有一个Worker，而每个Worker默认只会为当前应用程序分配一个Executor来执行Task，但实际上通过配置spark-env.sh可以让每台host上有若干个Worker，而每个Worker下面又可以有若干个Executor。
 5. 默认情况下Spark的Executor会尽可能占用当前机器上尽量多的Core，这样带来的一个好处就是可以最大化的提高计算的并行度，减少一个Job中任务运行的批次，但带来的一个风险就是如果每个Task占用内存比较大，就需要频繁的spill over或者有更多的OOM的风险。
 6. 当你经常发现机器频繁的OOM的时候，可以考虑的一种方式就是减少并行度，这样同样的内存空间并行运算的任务少了，那么对内存的占用就更少了，也就减少了OOM的可能性。
 7. 处理Spark Job的过程中如果出现特别多的小文件，这时候就可以通过 coalesce来减少Partition的数量，进而减少并行运算的Task的数量来减少过多任务的开辟，从而提升硬件的使用效率。
 8. 处理Spark Job时候如果发现某些Task运行的特别慢，这个时候应该考虑增加任务的并行度，减少每个Partition的数据量来提高执行效率。
 9. 处理Spark Job时候如果发现某些Task运行的特别慢另外一个处理办法是增加并行的Executor的个数，这样每个Executor分配的计算资源就变少了，可以提升硬件的整体使用效率。
 10. 处理Spark Job时候如果发现比较容易内存溢出，一个比较有效的办法就是增加task的并行度，这样每个Task处理的Partition的数据量就变少了，减少了OOM的可能性。
 11. 处理Spark Job时候如果发现比较容易内存溢出，另外一个比较有效的办法是减少并行的Executor数量，这样每个Executor就可以分配到更多的内存，进而增加每个Task使用的内存数量，降低OOM的风险。
 12. 提升Spark硬件尤其是CPU使用率的一个方式就是增加Executor的并行度，但是如果Executor过多的话，直接分配在每个Executor的内存就大大减少，在内存中的操作就减少，基于磁盘的操作就越来越多，导致性能越来越差。
 13. 适当设置Partition分片数是非常重要的，过少的Partition分片数可能会因为每个Partition数据量太大而导致OOM以及频繁的GC，而过多的Partition分片数据可能会因为每个Partition数据量太小而导致执行效率低下。
 14. 如果Spark中CPU的使用率不够高，可以考虑为当前的程序分配更多的Executor，或者增加更多的Worker实例来充分的使用多核的潜能。
 15. 性能调优的有效性是暂时的！！！例如为当前的应用程序增加Executor可能在一开始可以提高性能（例如CPU的使用率提高等），但是随着Executor越来越多，性能可能会下降！！！因为Executor越来越多的时候，为每个Executor分配的内存就越来越少，Task执行过程中可用的内存就越来越少，这个时候就要频繁的Spill over到磁盘，此时自然而然的导致性能变差。
 16. 实际执行Spark Job的时候要根据输入数据和每个Executor分配的Memory来决定执行时候的并行度，实际上一个简单的事实是：每个Core可以考虑分配2~3个Task；
 17. 默认情况下Executor的60%的内存被用来作为RDD的缓存，40%的内存被用来作为对象的创建空间，设置是通过spark.storage.memoryFraction来进行的。
 18. GC一般不能超过CPU的2%的时间。


我们在实际运行的时候，一般都会根据输入和具体的Executor内存大小，来确定使用多少Core！

##二：Spark性能优化招式

 1. Broadcast，如果Task在运行的过程中使用超过20KB大小的静态大对象，这个时候一般都要考虑使用Broadcast，例如一个大表Join一个小表，此时如果使用Broadcast把小表广播出去，这个时候大表就只需要静静的做一个美男子在自己的节点上待着，等待小表的数据到来！
 
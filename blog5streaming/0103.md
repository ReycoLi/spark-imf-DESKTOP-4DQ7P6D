# 第103课：动手实战联合使用Spark Streaming、Broadcast、Accumulator实现在线黑名单过滤和计数

标签： sparkIMF

---

如果你在实际开发环境中用过广播，一般情况下表明你的水平还是不错的，为什么？ 

* 首先是用广播的人他已经基本上脱离了最简单原始的RDD操作。
* 其实在企业级实际开发中，广播一个非常重要的高级技术。

广播高级在什么地方？
广播联合使用累加器！

##Broadcast和计数器 都不是我们想象的那么简单！

它们两者结合自定义的，会发生非常强大的作用。很多一线互联网的公司，它们很多复杂的业务都需要在我们联合使用和自定义广播接收器和计数器的基础上进行的。

##代码实战：联合使用Spark Streaming、Broadcast、Accumulator实现在线黑名单过滤和计数

SparkStreamingBroadcastAccumulator.java

```java
package com.dtspark.sparkapps.streaming;

import org.apache.spark.Accumulator;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.broadcast.Broadcast;
import org.apache.spark.streaming.Durations;
import org.apache.spark.streaming.Time;
import org.apache.spark.streaming.api.java.JavaPairDStream;
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;
import scala.Tuple2;

import java.util.Arrays;
import java.util.List;

/**
 * 第103课：动手实战联合使用Spark Streaming、Broadcast、Accumulator实现在线黑名单过滤和计数
 * Created by Limaoran on 2016/7/14.
 */
public class SparkStreamingBroadcastAccumulator {

    private static volatile Broadcast<List<String>> broadcastList;
    private static volatile Accumulator<Integer> accumulator;

    public static void main(String[] args) {
        SparkConf conf = new SparkConf().setAppName("SparkStreamingBroadcastAccumulator")
                .setMaster("local[4]");
        JavaStreamingContext jsc = new JavaStreamingContext(conf, Durations.seconds(5));

        //没有action的话，广播不会发出
        /**
         * 使用Broadcast广播黑名单到每个Executor
         */
        broadcastList = jsc.sparkContext().broadcast(Arrays.asList("Hadoop","Mahout","Hive"));
        /**
         * 全局计数器，用于统计在线过滤了多少个黑名单
         */
        accumulator = jsc.sparkContext().accumulator(0,"OnlineBlackListCounter");

        JavaReceiverInputDStream<String> lines = jsc.socketTextStream("Master", 9999);

        JavaPairDStream<String,Integer> wordCount = lines.flatMap(line->Arrays.asList(line.split(" "))).mapToPair(line -> {
            return new Tuple2(line, 1);
        });
        JavaPairDStream<String,Integer> wordsCount = wordCount.reduceByKey((Integer v1, Integer v2) -> v1 + v2);

        wordsCount.foreachRDD((JavaPairRDD<String, Integer> rdd, Time time) -> {
            JavaPairRDD<String, Integer> resultRDD = rdd.filter(wordPair -> {
                if (broadcastList.getValue().contains(wordPair._1())) {
                    accumulator.add(wordPair._2());
                    return false;   //false，过滤掉
                } else {
                    return true;
                }
            });
            resultRDD.foreach(tuple2 -> {
                System.out.println("内容："+tuple2._1()+"，出现次数："+tuple2._2());
            });
            System.out.println("黑名单：" + broadcastList.value().toString() + "，出现了" + accumulator.value() + "次");
        });

        jsc.start();
        jsc.awaitTermination();
    }
}
```

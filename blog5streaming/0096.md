# 第96课：通过Spark Streaming的foreachRDD把处理后的数据写入外部存储系统中

标签： sparkIMF

---

##foreachRDD解析

###这段代码逻辑是错的！

```scala
dstream.foreachRDD { rdd =>
  //这个地方的代码是在Driver中完成的
  val connection = createNewConnection()  // executed at the driver
  rdd.foreach { record =>
    //这个地方的代码是在Worker中的Executor中完成的！
    connection.send(record) // executed at the worker
  }
}
```

写foreachRDD代码的时候，这个东西不是针对RDD编程，所以它就不是RDD里面的元素，它就不是在Worker的Executor中执行的！

我们一个是在Driver中，一个是在Executor中要用这个连接器，这要求connection必须能够序列化！我们一般说连接数据库之类的，我们在什么地方执行就在什么地方连接数据库，而不是说在这个地方连接数据库，然后用序列化传到另外一台机器的JVM中让它反序列化继续连接！所以你一想**这件事情肯定是错的！**！！

因为这个RDD的foreach的时候它就是在Executor中执行，那在Executor中执行的时候它要用connection的话，**那我们这个connection就必须随着我们的任务广播到Executor中！**

Connection跟网络通信有关，所以不能序列化！

###正确的代码，但是有性能问题

```scala


dstream.foreachRDD { rdd =>
  rdd.foreach { record =>
    //在Worker的Executor中实例化Connection
    val connection = createNewConnection()
    connection.send(record)
    connection.close()
  }
}
```

在Worker的Executor中实例化Connection，这个时候就不需要广播了！运行的时候创建这个示例。

这个方式可以运行，但是每条记录创建一个连接器，效率和性能是个大问题。内存很快就耗尽崩溃了。


###正确的代码（高效的方式）

```scala
dstream.foreachRDD { rdd =>
  rdd.foreachPartition { partitionOfRecords =>
    val connection = createNewConnection()
    partitionOfRecords.foreach(record => connection.send(record))
    connection.close()
  }
}
```

**这种方式高效很多！**

对每个Partition创建一个连接器，然后这个Partition再foreach，复用这个连接器把数据发过去，然后再关闭掉！


###更高效的方式

我们在一台机器上会有很多Partition，所以有必要复用这个连接器！

```scala
dstream.foreachRDD { rdd =>
  rdd.foreachPartition { partitionOfRecords =>
    // ConnectionPool is a static, lazily initialized pool of connections
    val connection = ConnectionPool.getConnection()
    partitionOfRecords.foreach(record => connection.send(record))
    ConnectionPool.returnConnection(connection)  // return to the pool for future reuse
  }
}
```
它所创建的连接池是指在Executor内部创建连接池！一个Executor共享一个连接池！


###使用DStream的foreachRDD会不会导致我们整个DStream的执行呢？
不会！foreachRDD不会导致DStream的执行！你要向让它执行，里面的RDD必须有action触发！


##额外提示：

<font color='red'>
**foreachPartition可以构建神奇的功能！这个神奇的功能就是它可以让底层的数据变化！**

Spark基于RDD进行编程的时候，RDD的数据是不变的，这是RDD的规则。但是如果你擅长使用foreachPartition的话，底层的数据可以改变！因为Spark的RDD是分布式编程，我们有时候底层的数据有可能改变，这个改变的有时候是我们的一种业务需要！
</font>


##来自Spark官方Demo的过滤黑名单（结合了广播、累加器）

[spark-src/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala](https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala)

```scala
object WordBlacklist {

  @volatile private var instance: Broadcast[Seq[String]] = null

  def getInstance(sc: SparkContext): Broadcast[Seq[String]] = {
    if (instance == null) {
      synchronized {
        if (instance == null) {
          val wordBlacklist = Seq("a", "b", "c")
          instance = sc.broadcast(wordBlacklist)
        }
      }
    }
    instance
  }
}

object DroppedWordsCounter {

  @volatile private var instance: Accumulator[Long] = null

  def getInstance(sc: SparkContext): Accumulator[Long] = {
    if (instance == null) {
      synchronized {
        if (instance == null) {
          instance = sc.accumulator(0L, "WordsInBlacklistCounter")
        }
      }
    }
    instance
  }
}

wordCounts.foreachRDD((rdd: RDD[(String, Int)], time: Time) => {
  // Get or register the blacklist Broadcast
  val blacklist = WordBlacklist.getInstance(rdd.sparkContext)
  // Get or register the droppedWordsCounter Accumulator
  val droppedWordsCounter = DroppedWordsCounter.getInstance(rdd.sparkContext)
  // Use blacklist to drop words and use droppedWordsCounter to count them
  val counts = rdd.filter { case (word, count) =>
    if (blacklist.value.contains(word)) {
      droppedWordsCounter += count
      false
    } else {
      true
    }
  }.collect()
  val output = "Counts at time " + time + " " + counts
})
```

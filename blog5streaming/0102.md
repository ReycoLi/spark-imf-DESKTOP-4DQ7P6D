# 第102课：动手实战Spark Streaming自定义Receiver并进行调试和测试

标签： sparkIMF

---

大多数自定义Receiver都是基于网络的。

[自定义Receiver官方文档](http://spark.apache.org/docs/latest/streaming-custom-receivers.html)

使用StreamingContext.networkStream
```scala
  /**
   * Create an input stream with any arbitrary user implemented receiver.
   * Find more details at: http://spark.apache.org/docs/latest/streaming-custom-receivers.html
   * @param receiver Custom implementation of Receiver
   *
   * @deprecated As of 1.0.0", replaced by `receiverStream`.
   */
  @deprecated("Use receiverStream", "1.0.0")
  def networkStream[T: ClassTag](receiver: Receiver[T]): ReceiverInputDStream[T] = {
    withNamedScope("network stream") {
      receiverStream(receiver)
    }
  }
```

##代码示例

###Scala版本

[CustomReceiver.scala](https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala)

```scala
package org.apache.spark.examples.streaming 


import java.io.{BufferedReader, InputStreamReader} 
import java.net.Socket 
import java.nio.charset.StandardCharsets 


import org.apache.spark.SparkConf 
import org.apache.spark.internal.Logging 
import org.apache.spark.storage.StorageLevel 
import org.apache.spark.streaming.{Seconds, StreamingContext} 
import org.apache.spark.streaming.receiver.Receiver 


/** 
 * Custom Receiver that receives data over a socket. Received bytes are interpreted as 
 * text and \n delimited lines are considered as records. They are then counted and printed. 
 * 
 * To run this on your local machine, you need to first run a Netcat server 
 *    `$ nc -lk 9999` 
 * and then run the example 
 *    `$ bin/run-example org.apache.spark.examples.streaming.CustomReceiver localhost 9999` 
 */ 
object CustomReceiver { 
  def main(args: Array[String]) { 
    if (args.length < 2) { 
      System.err.println("Usage: CustomReceiver <hostname> <port>") 
      System.exit(1) 
    } 


    StreamingExamples.setStreamingLogLevels() 


    // Create the context with a 1 second batch size 
    val sparkConf = new SparkConf().setAppName("CustomReceiver") 
    val ssc = new StreamingContext(sparkConf, Seconds(1)) 


    // Create an input stream with the custom receiver on target ip:port and count the 
    // words in input stream of \n delimited text (eg. generated by 'nc') 
    val lines = ssc.receiverStream(new CustomReceiver(args(0), args(1).toInt)) 
    val words = lines.flatMap(_.split(" ")) 
    val wordCounts = words.map(x => (x, 1)).reduceByKey(_ + _) 
    wordCounts.print() 
    ssc.start() 
    ssc.awaitTermination() 
  } 
} 

class CustomReceiver(host: String, port: Int) 
  extends Receiver[String](StorageLevel.MEMORY_AND_DISK_2) with Logging { 

  def onStart() { 
    // Start the thread that receives data over a connection 
    new Thread("Socket Receiver") { 
      override def run() { receive() } 
    }.start() 
  } 

  def onStop() { 
   // There is nothing much to do as the thread calling receive() 
   // is designed to stop by itself isStopped() returns false 
  } 
  
  /** Create a socket connection and receive data until receiver is stopped */ 
  private def receive() { 
   var socket: Socket = null 
   var userInput: String = null 
   try { 
     logInfo("Connecting to " + host + ":" + port) 
     socket = new Socket(host, port) 
     logInfo("Connected to " + host + ":" + port) 
     val reader = new BufferedReader( 
       new InputStreamReader(socket.getInputStream(), StandardCharsets.UTF_8)) 
     userInput = reader.readLine() 
     while(!isStopped && userInput != null) { 
       store(userInput) 
       userInput = reader.readLine() 
     } 
     reader.close() 
     socket.close() 
     logInfo("Stopped receiving") 
     restart("Trying to connect again") 
   } catch { 
     case e: java.net.ConnectException => 
       restart("Error connecting to " + host + ":" + port, e) 
     case t: Throwable => 
       restart("Error receiving data", t) 
   } 
  } 
} 
```

###Java版本

[JavaCustomReceiver.java](https://github.com/apache/spark/blob/master/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java)

##Java版本自定义Receiver

MyReceiverWordCountOnline.java

```java
package com.dtspark.sparkapps.streaming;

import com.google.common.io.Closeables;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.storage.StorageLevel;
import org.apache.spark.streaming.Duration;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairDStream;
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;
import org.apache.spark.streaming.receiver.Receiver;
import scala.Tuple2;


import java.io.BufferedReader;
import java.io.InputStreamReader;
import java.net.ConnectException;
import java.net.Socket;
import java.nio.charset.StandardCharsets;
import java.util.Arrays;
import java.util.Iterator;
import java.util.regex.Pattern;
/**
 *
 * Created by Limaoran on 2016/7/14.
 *
 * Custom Receiver that receives data over a socket. Received bytes is interpreted as
 * text and \n delimited lines are considered as records. They are then counted and printed.
 *
 * Usage: JavaCustomReceiver <master> <hostname> <port>
 *   <master> is the Spark master URL. In local mode, <master> should be 'local[n]' with n > 1.
 *   <hostname> and <port> of the TCP server that Spark Streaming would connect to receive data.
 *
 * To run this on your local machine, you need to first run a Netcat server
 *    `$ nc -lk 9999`
 *    输入内容：Life is short you need Spark
 * and then run the example
 *    `$ bin/run-example org.apache.spark.examples.streaming.JavaCustomReceiver localhost 9999`
 */
public class MyReceiverWordCountOnline extends Receiver<String> {
    private static final Pattern SPACE = Pattern.compile(" ");

    public static void main(String[] args) throws Exception {
        // Create the context with a 1 second batch size
        SparkConf sparkConf = new SparkConf().setAppName("MyReceiverWordCountOnline").setMaster("local[4]");
        JavaStreamingContext ssc = new JavaStreamingContext(sparkConf, new Duration(1000*10));

        // Create an input stream with the custom receiver on target ip:port and count the
        // words in input stream of \n delimited text (eg. generated by 'nc')
        JavaReceiverInputDStream<String> lines = ssc.receiverStream(
                    new MyReceiverWordCountOnline("Master", 9999));
        JavaDStream<String> words = lines.flatMap(line->{
                return Arrays.asList(SPACE.split(line));
        });
        JavaPairDStream<String, Integer> wordCounts = words.mapToPair(
                new PairFunction<String, String, Integer>() {
                    @Override public Tuple2<String, Integer> call(String s) {
                        return new Tuple2<>(s, 1);
                    }
                }).reduceByKey(new Function2<Integer, Integer, Integer>() {
            @Override
            public Integer call(Integer i1, Integer i2) {
                return i1 + i2;
            }
        });

        wordCounts.print();
        ssc.start();
        ssc.awaitTermination();
    }
    // ============= Receiver code that receives data over a socket ==============
    String host = null;
    int port = -1;

    public MyReceiverWordCountOnline(String host_ , int port_) {
        super(StorageLevel.MEMORY_AND_DISK_2());
        host = host_;
        port = port_;
    }

    public void onStart() {
        // Start the thread that receives data over a connection
        new Thread()  {
            @Override public void run() {
                receive();
            }
        }.start();
    }

    public void onStop() {
        // There is nothing much to do as the thread calling receive()
        // is designed to stop by itself isStopped() returns false
    }

    /** Create a socket connection and receive data until receiver is stopped */
    private void receive() {
        try {
            Socket socket = null;
            BufferedReader reader = null;
            String userInput = null;
            try {
                // connect to the server
                socket = new Socket(host, port);
                reader = new BufferedReader(
                        new InputStreamReader(socket.getInputStream(), StandardCharsets.UTF_8));
                // Until stopped or connection broken continue reading
                while (!isStopped() && (userInput = reader.readLine()) != null) {
                    System.out.println("Received data '" + userInput + "'");
                    store(userInput);
                }
            } finally {
                Closeables.close(reader, /* swallowIOException = */ true);
                Closeables.close(socket,  /* swallowIOException = */ true);
            }
            // Restart in an attempt to connect again when server is active again
            restart("Trying to connect again");
        } catch(ConnectException ce) {
            // restart if could not connect to server
            restart("Could not connect", ce);
        } catch(Throwable t) {
            restart("Error receiving data", t);
        }
    }

    @Override
    public StorageLevel storageLevel() {
        return StorageLevel.MEMORY_AND_DISK_2();
    }
}
```

###测试数据
```sh
# nc -lk 9999
Life is short you need Spark
```

###测试结果
```text
Received data 'Life is short you need Spark'
-------------------------------------------
Time: 1468474900000 ms
-------------------------------------------
(short,1)
(Life,1)
(Spark,1)
(is,1)
(need,1)
(you,1)
```
